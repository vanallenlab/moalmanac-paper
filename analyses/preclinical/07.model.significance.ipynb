{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate model significance\n",
    "We test models to see if they are significantly different from one another. We use [this reference](https://engineering.purdue.edu/kak/SignificanceTesting.pdf). \n",
    "\n",
    "This notebook could later be improved to do all pairwise comparisons and compare all against random. In general, it seems that all are better than random. This notebook is written as delta mAP as the test statistic, though in practice, we also considered AP@1-5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "def read_pickle(handle):\n",
    "    return pickle.load(open(handle, \"rb\"))\n",
    "\n",
    "models = read_pickle('tables/models.evaluated.pkl')\n",
    "models_random = read_pickle('tables/models.random.evaluated.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['jaccard-almanac-genes', 'jaccard-almanac-feature-types', 'jaccard-almanac-features', 'jaccard-cgc-genes', 'jaccard-cgc-feature-types', 'compatibility', 'nonsynonymous-variant-count', 'pca-almanac-genes', 'pca-cgc-genes', 'multi-pass-sort_fda-cgc', 'snf_fda-cgc-genes', 'snf_cgc', 'snf_fda-cgc', 'snf_almanac', 'somatic-tree'])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['random_mean', 'random_plus_one_std', 'random_minus_one_std'])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models_random.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_two_models(case_dict, comparison_dict, case_label, comparison_label, N):\n",
    "    case_mAP = case_dict['mean_average_precision']\n",
    "    comparison_mAP = comparison_dict['mean_average_precision']\n",
    "    delta_mAP = case_mAP - comparison_mAP\n",
    "    \n",
    "    aps = pd.concat([\n",
    "        case_dict['average_precision'].rename(case_label),\n",
    "        comparison_dict['average_precision'].rename(comparison_label)\n",
    "    ], axis=1)\n",
    "    aps['shuffle_case'] = 0\n",
    "    aps['shuffle_comparison'] = 0\n",
    "    \n",
    "    delta_mAPs = pd.Series(index=range(0, N), dtype=float)\n",
    "    for seed in delta_mAPs.index:\n",
    "        rng = np.random.default_rng(seed=seed)\n",
    "        aps['rng'] = rng.binomial(1, 0.5, aps.shape[0])\n",
    "\n",
    "        aps.loc[aps['rng'].eq(1), 'shuffle_case'] = aps.loc[aps['rng'].eq(1), case_label]\n",
    "        aps.loc[aps['rng'].eq(1), 'shuffle_comparison'] = aps.loc[aps['rng'].eq(1), comparison_label]\n",
    "        aps.loc[aps['rng'].eq(0), 'shuffle_case'] = aps.loc[aps['rng'].eq(0), comparison_label]\n",
    "        aps.loc[aps['rng'].eq(0), 'shuffle_comparison'] = aps.loc[aps['rng'].eq(0), case_label]\n",
    "    \n",
    "        shuffled_case_mAP = aps['shuffle_case'].mean()\n",
    "        shuffled_comparison_mAP = aps['shuffle_comparison'].mean()\n",
    "        shuffled_delta_mAP = shuffled_case_mAP - shuffled_comparison_mAP\n",
    "        delta_mAPs.loc[seed] = shuffled_delta_mAP\n",
    "    return delta_mAP, delta_mAPs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "snf_fda-cgc AP@1: 0.19363395225464192\n",
      "random_mean AP@1: 0.09549071618037135\n",
      "snf_fda-cgc mAP: 0.12874146850322937\n",
      "random_mean mAP: 0.1104324533000405\n",
      "delta mAP: 0.018309015203188866\n",
      "pvalue: 0.0021\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False    9979\n",
       "True       21\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "case = 'snf_fda-cgc'\n",
    "comparison = 'random_mean' # random_mean\n",
    "\n",
    "case_model = models[case]\n",
    "#comparison_model = models[comparison]\n",
    "comparison_model = models_random[comparison] # models_random[comparison]\n",
    "\n",
    "delta_mAP, series = compare_two_models(case_model, comparison_model, case, comparison, 10000)\n",
    "series_value_counts = series.abs().ge(abs(delta_mAP)).value_counts()\n",
    "if True in series_value_counts.index:\n",
    "    pvalue = series_value_counts[True] / series.shape[0]\n",
    "else:\n",
    "    pvalue = 0\n",
    "\n",
    "print(f\"{case} AP@1: {case_model['ap@k'][1]}\")\n",
    "print(f\"{comparison} AP@1: {comparison_model['ap@k'][1]}\")\n",
    "print(f\"{case} mAP: {case_model['mean_average_precision']}\")\n",
    "print(f\"{comparison} mAP: {comparison_model['mean_average_precision']}\")\n",
    "print(f\"delta mAP: {delta_mAP}\")\n",
    "print(f\"pvalue: {pvalue}\")\n",
    "print('')\n",
    "\n",
    "series.abs().ge(abs(delta_mAP)).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['jaccard-almanac-genes',\n",
       " 'jaccard-almanac-feature-types',\n",
       " 'jaccard-almanac-features',\n",
       " 'jaccard-cgc-genes',\n",
       " 'jaccard-cgc-feature-types',\n",
       " 'compatibility',\n",
       " 'nonsynonymous-variant-count',\n",
       " 'pca-almanac-genes',\n",
       " 'pca-cgc-genes',\n",
       " 'multi-pass-sort_fda-cgc',\n",
       " 'snf_fda-cgc-genes',\n",
       " 'snf_cgc',\n",
       " 'snf_fda-cgc',\n",
       " 'snf_almanac',\n",
       " 'somatic-tree']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(models.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_models = list(models.keys())\n",
    "df = pd.DataFrame(0, index=all_models, columns=all_models)\n",
    "for model_row in all_models:\n",
    "    for model_col in all_models:\n",
    "        case_model = models[model_row]\n",
    "        comparison_model = models[model_col]\n",
    "        #comparison_model = models_random[comparison] # models_random[comparison]\n",
    "\n",
    "        delta_mAP, series = compare_two_models(case_model, comparison_model, case, comparison, 10000)\n",
    "        series_value_counts = series.abs().ge(abs(delta_mAP)).value_counts()\n",
    "        if True in series_value_counts.index:\n",
    "            pvalue = series_value_counts[True] / series.shape[0]\n",
    "        else:\n",
    "            pvalue = 0\n",
    "        \n",
    "        df.loc[model_row, model_col] = pvalue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('tables/pairwise-model-comparison.txt', sep='\\t', index_label='model-id')\n",
    "df.to_excel('tables/Supplementary Table 6.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "moalmanac-paper",
   "language": "python",
   "name": "moalmanac-paper"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
